{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef06d11-0764-414c-9fb8-6549cc3c3672",
   "metadata": {},
   "source": [
    "# Getting Set Up\n",
    "\n",
    "Running PyROA you have a two options:\n",
    "\n",
    "1. Install PyROA package and use it directly\n",
    "2. Install pyPETaL package, which is a \"wrapper/pipeline\" code that simplifies inputs, use other lag detection software, at the cost of a bit less control of inputs\n",
    "\n",
    "Both are great options, I've tested both and gotten similar results, mainly it's only annoying to use pyPETaL if you want the output plots to be anything but their default, which is the biggest draw back since you may want to present your results in more than one way. That _some_ priors are calculated for you, which should probably be fine, but using the PyROA package give more control. (pyPETaL may be easier to learn on though).\n",
    "\n",
    "### PyROA Install\n",
    "Straight foward installation, just run the following command in your terminal:\n",
    "```\n",
    "    pip install pyroa\n",
    "```\n",
    "Here's the [PyROA GitHub Link](https://github.com/FergusDonnan/PyROA) which has their publication for in depth detail, and further examples/documentation\n",
    "\n",
    "### pyPETaL Install\n",
    "Run the following in terminal\n",
    "```\n",
    "    pip install pypetal\n",
    "```\n",
    "I'll be writing this tutorial for PyROA, so if you choose to use pyPETaL, just follow this up until the part I give example code. \n",
    "Then, just follow the [pyPETaL example usage of PyROA at this link](https://pypetal.readthedocs.io/en/latest/pyroa_toc.html)\n",
    "\n",
    "### Issues After Install?\n",
    "Should be straightforward, but the only issues I've had are missing packages PyROA uses. Just install the package in the error code if this is the case \n",
    "```\n",
    "    pip install <package-name-here>\n",
    "```\n",
    "Otherwise, PyROA may require a specific version of numpy? If anything look at the issues tab on [their github](https://github.com/FergusDonnan/PyROA) for this.\n",
    "Installing different version of numpy is as follows\n",
    "THOUGH! You may want to use a seperate conda enviornemt BEFOREHAND (google how to make seperate conda enviornment p straight forward super useful), that way if you use other packages that need your current numpy version you don't mess that up.\n",
    "```\n",
    "    pip install numpy==<version-number-here>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f43b47-820d-4f27-adf0-3b7733fe0253",
   "metadata": {},
   "source": [
    "# PyROA Basics\n",
    "PyROA uses a running optimal average (ROA) model in order to simultaneously fit your input lightcurves. This is essentially exactly as it sounds, an optimally calculated average of your input photometry, which prioritizes this average calculation to epochs more \"local\" in time/MJD. The specifics of this model can be found in [Donnan et al. 2021](https://ui.adsabs.harvard.edu/abs/2021arXiv210712318D/abstract), but you don't need to know too much more other than this model fits all of your light curves simulatneously! (powerful stuff) Here's the basic run down of the model fit parameters used in the fit:\n",
    "\n",
    "## Parameters and Priors\n",
    "\n",
    "| Fit Parameters   | Description | \n",
    "| -------- | ------- |\n",
    "| $A_i$  | Fraction of the RMS flux (model/observed) for your $i$th input lightcurve |\n",
    "| $B_i$ | Fraction of the mean flux (model/observed) for your $i$th input lightcurve |\n",
    "| $\\tau_i$   | Lag measured between your bluest and $i$th lightcurve model |\n",
    "| $\\sigma_i$   | *Optional* extra variance that can be added to your $i$th lightcurve model (helps with fitting!) |\n",
    "| $\\Delta$   | The \"window\" in $t$ which all your lightcurve models will prioritize when calculating the ROA  |\n",
    "\n",
    "\n",
    "\n",
    "PyROA runs a built in markov chain monte carlo (MCMC) fitting your data with a preset amount of walkers, over an input number of iterations. \n",
    "\n",
    "### Priors\n",
    "If you're unfamiliar with the term, Bayesian statistics models generally will require prior knowledge of your fit parameters to know where the model should search. These can come in the form of probability distributions of any shape where the user assumes these model parameters should be, but often (and in PyROA's case) we assume a uniform prior distribution. (i.e. between lower and upper bounds).\n",
    "\n",
    "PyROA will want you to input a list of upper and lower bounds to build a prior, as shown below.\n",
    "\n",
    "\n",
    "```\n",
    "    priors = [[A_lower, A_upper], [B_lower, B_upper], [tau_lower, tau_upper],[delta_lower, delta_upper], [sig_lower, sig_upper]]\n",
    "```\n",
    "\n",
    "THIS is where YOU have the most control of your fits. More specifically...\n",
    "\n",
    "* A and B probably should stick around [0.5, 2.0], though can be adjusted to be wider if needed.\n",
    "* [tau_lower, tau_upper] should porbably be centered around 0, just use reasonable bounds for lags you'd expect.\n",
    "* The Delta prior may be the most sensitive! Try to keep the upper bound around ~5 times your cadence, but play around with this one a LOT. Having a smaller window mean your lightcurve model fixate on finer changes \n",
    "* $\\sigma$ will also need some playing around with. With more range, the model will be more flexible, which can help it accomidate differences in variability between lightcurves.\n",
    "\n",
    "Here's a starting point :)\n",
    "```\n",
    "    priors = [[0.5, 2.0],[0.5, 2.0], [0.0, 20.0], [0.05, 5.0], [0.0, 10.0]]\n",
    "```\n",
    "\n",
    "\n",
    "## PyROA Inputs\n",
    "\n",
    "Here is what the PyROA command looks like with it's basic inputs.\n",
    "\n",
    "```\n",
    "    fit = PyROA.Fit(datadir, objName, filters, priors, add_var=True, plot_corner=True, init_tau = init_tau, init_delta = init_delta, Nsamples=Nsamples, Nburnin=Nburn)\n",
    "    \n",
    "```\n",
    "\n",
    "IMPORTANT!!!\n",
    "The way data is input is quite picky so datadir, objName, and filter CAREFULLY. Your filenames should be \"objName\" + \"filter\", and be dat files with coloums in the order of; 1) MJD, 2) flux, 3) flux_error.\n",
    "\n",
    "Input Descriptions:\n",
    "| Input   | Description | \n",
    "| -------- | ------- |\n",
    "| datadir  | File location to the folder of your lightcurves. In this folder should one dat file for each lightcurve. |\n",
    "| objName | Your file names in datadir should be \"objName\" + \"filter\" so objName is the beginning bit of each file name. ex) \"sdssrm101\" in \"sdssrm101g filter.dat\"|\n",
    "| filters   | list of str, which are your filters/emission feature names. Ex) filters = [\"g filter\", \"r filter\", \"i filter\"] where you have the files \"sdssrm101g filter.dat\" etc. |\n",
    "| priors   | list of upper and lower bounds for each fit parameter (see prior description above) |\n",
    "| add_var   | Here you can choose whether you want the ROA model to include $\\sigma_i$ the extra variance. It usually fits better with it, but not always. |\n",
    "| plot_corner   | Whether or not you want PyROA to save a pdf of the posterior fit parameters distributions |\n",
    "| init_tau   | list if initial guesses for each lag. If you have $n$ lightcurves, the list should be $n-1$ length |\n",
    "| init_delta   | Initial guess for delta. May just want to give center of prior range. |\n",
    "| Nsamples   | Number of MCMC iterations. Try 10000, you can add more if you think the model needs more time to settle on good fit parameters |\n",
    "| Nburnin   | PyROA will disregard the first \"Nburnin\" iterations of the MCMC. This is useful for complex models that need thousands of iterations to fit there higher number of parameters (4 * $n$ lightcurves + 1 params!!!)|\n",
    "\n",
    "\n",
    "## PyROA Outputs\n",
    "\n",
    "PyROA will store it's outputs in a couple files, which they save right to whatever your current working directory is (eww). These files are...\n",
    "\n",
    "* A corner plot\n",
    "* \"samples.obj\" - a pickle object containting the total unflattened samples\n",
    "* \"samples_flat.obj\" - a pickle object containing the flattened samples with the \"burn-in\" removed\n",
    "* \"X_t.obj\" - a pickle object containting the driving lightcurve. This is a list in the form [t, X, X_errs], where t is the time grid, X is the value of the driving lightcurve, and X_errs is the error envelope from the running optimal average.\n",
    "* \"Lightcurve_models.obj\" - a pickle object containing the model for each lightcurve. This is a list of models where each model is an array with in the form [t, model, model_errs].\n",
    "\n",
    "Pickle files are just a method of data storage, my code below will give you the way to simply extract and plot your results.\n",
    "\n",
    "ALSO I suggest you make a new folder for organizing PyROA outputs, otherwise everytime it is run, you will simply continue to dump these files into your working directory, which the developers disregaurd for there users to simply build in a desired output directory (just throwing shade). The code below will also include a way to close these files and also move them to your desired output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154f111-b0fc-4acd-a7ea-ceae0d18771f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23ef94d-db18-4055-b267-cce330fc2b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages you will need\n",
    "\n",
    "# Enable inline plotting in notebook\n",
    "%matplotlib inline\n",
    "# Populate namespace with numerical python function library and matplotlib plotting library.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "print(np.__version__)\n",
    "\n",
    "\n",
    "from matplotlib import gridspec#\n",
    "from scipy import interpolate\n",
    "from astropy.io import ascii\n",
    "from astropy import units as u\n",
    "from scipy.stats import median_abs_deviation\n",
    "import collections\n",
    "from uncertainties import ufloat\n",
    "import math\n",
    "import PyROA\n",
    "import shutil\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ec2dea-73c8-43ac-a76f-becaceb6b132",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "Much of this example code (data included) is riped from the [example on the PyROA github](https://github.com/FergusDonnan/PyROA/blob/main/examples/Example_Usage.ipynb). I've just added my own little tweaks for the data output pretty much.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f026b3-a1e4-48be-a343-0659f8f17a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Inputs\n",
    "\n",
    "datadir = \"......../MockData/HighSN/\" #route to High SN data (feel free to try low SN too)\n",
    "objName=\"TestObj\" #these should be formatted right? feel free to double check\n",
    "filters=[\"1\",\"2\",\"3\"] #they just named the filters numerically\n",
    "init_tau = [5.0, 10.0] #initial guess for lags\n",
    "priors = [[0.5, 2.0],[0.5, 2.0], [0.0, 20.0], [0.05, 5.0], [0.0, 10.0]] #A, B, tau, sigma, delta (prior ranges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48581d-ce77-413b-8bd4-ad70dbedd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's a little function I use to move my output PyROA files to outputdirectory I want\n",
    "\n",
    "def move_pyroa_files(dir_to_move_to, dir_where_files_are):\n",
    "    \"\"\"Function that moves PyROA outputs to a directory of your choice.\n",
    "    Args:\n",
    "        dir_to_move_to (str): directory to move files to.\n",
    "        dir_where_files_are (str): directory where the files get placed. Usually itâ€™s the base directory that you open up in your code editor.\n",
    "    \"\"\"\n",
    "    files_to_move = ['CornerPlot1.pdf', 'samples.obj', 'samples_flat.obj', 'X_t.obj', 'Lightcurve_models.obj']\n",
    "    for file in files_to_move:\n",
    "        shutil.move(dir_where_files_are + file, dir_to_move_to + file)\n",
    "\n",
    "outputdir = #Output directory here for PyROA files\n",
    "workdir = '' #probably leave as '', otherwise write whatever you use as working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e68fc1-6fd2-41bb-925c-a2c8d1db44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run PyROA (this may take ~20 min depending on quality of data and Nsamples)\n",
    "\n",
    "fit = PyROA.Fit(datadir, objName, filters_scaled, priors, add_var=ADDvar, plot_corner=True, init_tau = init_tau, init_delta = init_delta, Nsamples=Nsamples, Nburnin=Nburn)\n",
    "\n",
    "#Move PyROA Files (otherwise they overwrite eachother)\n",
    "move_pyroa_files(outputdir, workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e87354-2b8f-410e-be1f-384903d6c075",
   "metadata": {},
   "source": [
    "# Walker Trace Plot\n",
    "The PyROA github example doesn't have this and there is now easy way to actually make this without some annoying looking into the devcode so you can use mine :) I don't think you'll need to edit any of this, but lmk otherwise and feel free to skip if so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74996a5-d478-49a9-a18c-141e99a29456",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(outputdir + \"samples.obj\",'rb')\n",
    "samples = pickle.load(file)\n",
    "\n",
    "row_labels = ['$A_i$', '$B_i$', '$\\\\tau_i$', '$\\\\sigma_i$']\n",
    "\n",
    "col_labels = [i[0:1] for i in filters]\n",
    "col_labels.append(\"$\\\\Delta$\")\n",
    "\n",
    "ncol = len(filters) + 1\n",
    "\n",
    "fig, ax = plt.subplots(4, ncol, figsize = (5*ncol, 4), sharex=True)\n",
    "\n",
    "for i in range(0, 4):\n",
    "    ax[i,0].set_ylabel(row_labels[i], fontsize = 28)\n",
    "\n",
    "\n",
    "ind=[[0,1,2], [3,4,5,6], [7,8,9,10], [11,12,13,14]]\n",
    "if len(filters) == 3:\n",
    "    ind=[[0,1,2], [3,4,5,6], [7,8,9,10]]\n",
    "\n",
    "if ADDvar == False:\n",
    "    ind=[[0,1], [2,3,4], [5,6,7], [8,9,10]]\n",
    "\n",
    "print(ind) \n",
    "    \n",
    "for i in range(0, ncol):\n",
    "    \n",
    "    for j in range(samples.shape[1]):\n",
    "        \n",
    "        \n",
    "        if i == ncol-1:\n",
    "            ax[0, i].plot(samples[:,j,-1], c='k', alpha=0.1)\n",
    "            continue\n",
    "        \n",
    "        ax[0,i].plot(samples[:,j,ind[i][0]], color='k', alpha = 0.1)\n",
    "        ax[1,i].plot(samples[:,j,ind[i][1]], color='k', alpha = 0.1)\n",
    "        \n",
    "        \n",
    "            \n",
    "        if ADDvar == True:\n",
    "            ax[3, i].plot(samples[:,j,ind[i][-1]], color='k', alpha = 0.1)\n",
    "            if i == 0:\n",
    "                ax[2,i].plot( np.zeros( samples.shape[0] ), c='k', alpha=0.1 )\n",
    "            else:\n",
    "                ax[2,i].plot(samples[:,j,ind[i][2]], color='k', alpha = 0.1)\n",
    "        else:\n",
    "            ax[3, i].plot(np.zeros( samples.shape[0] ), c='k', alpha=0.1 )\n",
    "            if i == 0:\n",
    "                ax[2,i].plot( np.zeros( samples.shape[0] ), c='k', alpha=0.1 )\n",
    "            else:\n",
    "                ax[2,i].plot(samples[:,j,ind[i][-1]], color='k', alpha = 0.1)\n",
    "        \n",
    "    for k in range(0,4):\n",
    "        if k == 0:\n",
    "            ax[k,i].set_title(col_labels[i], fontsize=28)\n",
    "        ax[k,i].axvline(Nburn, ls='--', color='r')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acfd9e-ea8d-4964-8c9a-c61b5bc6a78f",
   "metadata": {},
   "source": [
    "# Model Lag Plot\n",
    "This is pretty much ripped from the github example with a few quality of life tweaks. I have a more complex version, as I believe this may break if you choose add_var = False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39ec46-d65d-42aa-bd66-5d348ffd9415",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"font.family\": \"Sans\",  \n",
    "    \"font.serif\": [\"DejaVu\"],\n",
    "\"figure.figsize\":[40,30],\n",
    "\"font.size\": 30})  \n",
    "\n",
    "file = open(outputdir + \"samples_flat.obj\",'rb')\n",
    "samples_flat = pickle.load(file)\n",
    "file = open(outputdir + \"Lightcurve_models.obj\",'rb')\n",
    "models = pickle.load(file)\n",
    "\n",
    "\n",
    "#Split samples into chunks, 4 per lightcurve i.e A, B, tau, sig\n",
    "chunk_size=4\n",
    "transpose_samples = np.transpose(samples_flat)\n",
    "#Insert zero where tau_0 would be \n",
    "transpose_samples = np.insert(transpose_samples, [2], np.array([0.0]*len(transpose_samples[1])), axis=0)\n",
    "samples_chunks = [transpose_samples[i:i + chunk_size] for i in range(0, len(transpose_samples), chunk_size)] \n",
    "\n",
    "##########################################################################\n",
    "#Hugh wrote this part to display lags in the corner of the plots\n",
    "lag_dict = {}\n",
    "for i in range(0, len(filters)):\n",
    "    tau_samples = samples_chunks[i][tauind]\n",
    "    print(len(tau_samples))\n",
    "    lag_perc = np.percentile(tau_samples, [16, 50, 84])\n",
    "    if i == 0:\n",
    "        lag_text = \"$\\\\tau$=\" + str(lag_perc[1])[0:4] + \" days\"\n",
    "    else:\n",
    "        lag_text = \"$\\\\tau$=\" + str(lag_perc[1])[0:4] + \" days \\n(+\" + str(lag_perc[2]-lag_perc[1])[0:4] + \" -\" + str(lag_perc[1]-lag_perc[0])[0:4] + \")\"\n",
    "    lag_dict[str(filters[i])[0:1]] = lag_text\n",
    "print(lag_dict)\n",
    "##########################################################################\n",
    "\n",
    "fig = plt.figure(5)\n",
    "gs = fig.add_gridspec(len(filters), 2, hspace=0, wspace=0, width_ratios=[5, 1])\n",
    "axs= gs.subplots(sharex='col')\n",
    "\n",
    "band_colors=[\"royalblue\", \"darkcyan\", \"olivedrab\", \"#ff6f00\", \"#ef0000\", \"#610000\"]\n",
    "\n",
    "#Loop over lightcurves\n",
    "filters=[\"1\",\"2\",\"3\"]\n",
    "\n",
    "data=[]\n",
    "for i in range(len(filters)):\n",
    "    #Read in data\n",
    "    file = datadir + \"TestObj_\" + str(filters[i]) + \".dat\"\n",
    "    data.append(np.loadtxt(file))\n",
    "    mjd = data[i][:,0]\n",
    "    flux = data[i][:,1]\n",
    "    err = data[i][:,2]    \n",
    "    \n",
    "    #Add extra variance\n",
    "    sig = np.percentile(samples_chunks[i][-1], 50)\n",
    "    err = np.sqrt(err**2 + sig**2)\n",
    "    \n",
    "    #Plot Data\n",
    "    axs[i][0].errorbar(mjd, flux , yerr=err, ls='none', marker=\".\", color=band_colors[i], ms=20, elinewidth=5)\n",
    "    #Plot Model\n",
    "    t, m, errs = models[i]\n",
    "    axs[i][0].plot(t,m, color=\"black\", lw=3)\n",
    "    axs[i][0].fill_between(t, m+errs, m-errs, alpha=0.5, color=\"black\")\n",
    "    axs[i][0].set_xlabel(\"Time\")\n",
    "    axs[i][0].set_ylabel(\"Flux\")\n",
    "\n",
    "    #Plot Time delay posterior distributions\n",
    "    tau_samples = samples_chunks[i][2],\n",
    "    axs[i][1].hist(tau_samples, color=band_colors[i], bins=50)\n",
    "    axs[i][1].axvline(x = np.percentile(tau_samples, [16, 50, 84])[1], color=\"black\")\n",
    "    axs[i][1].axvline(x = np.percentile(tau_samples, [16, 50, 84])[0] , color=\"black\", ls=\"--\")\n",
    "    axs[i][1].axvline(x = np.percentile(tau_samples, [16, 50, 84])[2], color=\"black\",ls=\"--\")\n",
    "    axs[i][1].axvline(x = 0, color=\"black\",ls=\"--\")    \n",
    "    axs[i][1].set_xlabel(\"Time Delay \")\n",
    "    axs[0][0].set_title(\"Lightcurves\")\n",
    "    axs[0][1].set_title(\"Time Delay\")\n",
    "\n",
    "    #Writes the lag in the corner of PyROA plot\n",
    "    axs[i][1].text(0.7,0.85, lag_dict[fs[i]], horizontalalignment='center', verticalalignment='center', transform = axs[i][1].transAxes)\n",
    "    \n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
